# the loaded data type in MATLAB is struct with 2 fields: channels (100, 1, 1184923) and userLoc (1184923, 3)
# channels: (#ant, #sub, #user), userLoc: (#user, 3)
# And also note that each element of channels is complex number.
import numpy as np
import h5py as h5

def dataPrep(inputName=None, valPerc=0.3, save_shuffled_idx=False):
    with h5.File(inputName,'r') as f:
        fields = [k for k in f.keys()] # ['#refs#', 'dataset'], two groups
        nested = [k for k in f[fields[1]].keys()] # in 'dataset' group: ['channels', 'userLoc'], two datasets
        deepMIMO_data = f[fields[1]] # deepMIMO_data is a group (group 'dataset' of f) contains two datasets: ['channels', 'userLoc']
        data_channels = np.squeeze(np.array(deepMIMO_data[nested[0]]))
        # shape: (#users, #ant), in #ant dim, it is a tuple with real and imag parts of original data (real, imag)
        # data_userLoc = np.array(deepMIMO_data[nested[1]]) # shape: (3, #users)
        decoup = data_channels.view(np.float32).reshape(data_channels.shape + (2,))
        # shape: (#users, #ant, 2), decoup[0,0,0]=real, decoup[0,0,1]=imag
        X_real = decoup[:,:,0] # shape: (#users, #ant), all real parts of channels
        X_imag = decoup[:,:,1] # shape: (#users, #ant), all imag parts of channels
        # data_channels = concat(data_channels) # shape: (#users, #sub, #ant), in #ant dim, it is a complex number
        X = np.concatenate((X_real, X_imag), axis=-1)
        # shape: (#users, 2*#ant) with real parts for the first half and imag parts for the latter half
        # each row of X is what we want in the complex_fc_cpu layer: (h_r, h_i)

    print('Creating training and validation inputs')
    numTrain = np.floor((1 - valPerc) * X.shape[0]).astype('int')
    numVal = np.floor(valPerc * X.shape[0]).astype('int')
    print('Size of training dataset: ' + str(numTrain) + '\n' + 'Size of validation dataset: ' + str(numVal))
    shuffled_idx = np.random.permutation(X.shape[0])
    if save_shuffled_idx:
        np.save('shuffled_ind', shuffled_idx)
    X_shuffled = X[shuffled_idx,:]
    train_inp = X_shuffled[0:numTrain,:]
    val_inp = X_shuffled[numTrain:,:]
    # actually DO NOT use 'numVal', collect all the remaining data to the validation dataset

    return train_inp, val_inp

def load_data(tr_load_perc=1):
    train_inp = np.load('trainning_set.npy') # shape: (numTrain, 2*#ant)
    val_inp = np.load('validation_set.npy')
    total_train = train_inp.shape[0]
    return train_inp[:tr_load_perc * total_train,:], val_inp

'''
Data type and organization hints:
Information about train_inp (similar for val_inp):
1. type: numpy.ndarray
2. shape: (numTrain, 2*#ant), which means each row is one user's channel
3. data organization: in shape[1], it is (real, imag) of the channel generated by MATLAB,
that is, for example, if the antenna number is 64, then train_inp.shape[1] = 128,
with the first 64 elements the real part of the channel and second 64 imaginary part of the channel.
Type of shuffled_idx: numpy.ndarray with shape (#users,)
'''

# Debugging ONLY or generating datasets and save
# inputFile = 'F:\Dropbox (ASU)\Research\Paper_Codebook Learning\Codes\CodebookLearning_Dataset_Generation\CBL_O1_60_BS3_60GHz_1Path_Corrupted_norm.mat'
# train_inp, val_inp = dataPrep(inputName=inputFile, save_shuffled_idx=True)
# np.save('trainning_set', train_inp)
# np.save('validation_set', val_inp)